{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor,ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('D:\\pe_train.csv')\n",
    "test=pd.read_csv('D:\\pe_test.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb6e3ac8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train['PE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "train1 = train.drop('PE',axis = 1)\n",
    "trains = sc.fit_transform(train1)\n",
    "tests = sc.transform(test)\n",
    "y = train['PE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>PE</td>        <th>  R-squared:         </th> <td>   0.925</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.925</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>2.964e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 25 Jul 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:09:19</td>     <th>  Log-Likelihood:    </th> <td> -28292.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9568</td>      <th>  AIC:               </th> <td>5.659e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9563</td>      <th>  BIC:               </th> <td>5.663e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  466.4740</td> <td>    0.048</td> <td> 9798.631</td> <td> 0.000</td> <td>  466.381</td> <td>  466.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  -14.7064</td> <td>    0.116</td> <td> -126.580</td> <td> 0.000</td> <td>  -14.934</td> <td>  -14.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -2.9632</td> <td>    0.094</td> <td>  -31.451</td> <td> 0.000</td> <td>   -3.148</td> <td>   -2.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3341</td> <td>    0.057</td> <td>    5.818</td> <td> 0.000</td> <td>    0.222</td> <td>    0.447</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -2.3037</td> <td>    0.062</td> <td>  -37.145</td> <td> 0.000</td> <td>   -2.425</td> <td>   -2.182</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>412.122</td> <th>  Durbin-Watson:     </th> <td>   1.983</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1204.009</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.161</td>  <th>  Prob(JB):          </th> <td>3.57e-262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.708</td>  <th>  Cond. No.          </th> <td>    4.87</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     PE   R-squared:                       0.925\n",
       "Model:                            OLS   Adj. R-squared:                  0.925\n",
       "Method:                 Least Squares   F-statistic:                 2.964e+04\n",
       "Date:                Sat, 25 Jul 2020   Prob (F-statistic):               0.00\n",
       "Time:                        16:09:19   Log-Likelihood:                -28292.\n",
       "No. Observations:                9568   AIC:                         5.659e+04\n",
       "Df Residuals:                    9563   BIC:                         5.663e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        466.4740      0.048   9798.631      0.000     466.381     466.567\n",
       "x1           -14.7064      0.116   -126.580      0.000     -14.934     -14.479\n",
       "x2            -2.9632      0.094    -31.451      0.000      -3.148      -2.779\n",
       "x3             0.3341      0.057      5.818      0.000       0.222       0.447\n",
       "x4            -2.3037      0.062    -37.145      0.000      -2.425      -2.182\n",
       "==============================================================================\n",
       "Omnibus:                      412.122   Durbin-Watson:                   1.983\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1204.009\n",
       "Skew:                          -0.161   Prob(JB):                    3.57e-262\n",
       "Kurtosis:                       4.708   Cond. No.                         4.87\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Raw OLS model \n",
    "import statsmodels.api as sm\n",
    "X_constant = sm.add_constant(trains)\n",
    "model = sm.OLS(y, X_constant).fit()\n",
    "predictions = model.predict(X_constant)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b880276eba9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m  \u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m  seed=100)\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrains\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    542\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1367\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1368\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1370\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb=XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=6000,\n",
    " max_depth=6,\n",
    " colsample_bytree=0.8,\n",
    " seed=100)\n",
    "xgb_model=xgb.fit(trains,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_results= cross_val_score(xgb, trains, y,cv=5, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.6747999118112613"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xgb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = xgb_model.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = GradientBoostingRegressor(learning_rate =0.01,n_estimators=6500,max_depth=6)\n",
    "grd_model=grd.fit(trains,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_results= cross_val_score(grd, trains, y,cv=5, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.643109164713995"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = grd_model.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('PE',axis = 1)\n",
    "y = train['PE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains = sc.fit_transform(X_train)\n",
    "X_tests = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "lgb_fit_params={\"early_stopping_rounds\":100, \n",
    "            \"eval_metric\" : 'rmse', \n",
    "            \"eval_set\" : [(X_tests,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose':100\n",
    "           }\n",
    "lgb_params = {'boosting_type': 'gbdt',\n",
    " 'objective': 'regression',\n",
    " 'metric': 'rmse',\n",
    " 'verbose': 0,\n",
    " 'bagging_fraction': 0.8,\n",
    " 'bagging_freq': 1,\n",
    " 'lambda_l1': 0.01,\n",
    " 'lambda_l2': 0.01,\n",
    " 'learning_rate': 0.01,\n",
    " 'max_bin': 255,\n",
    " 'max_depth': 6,\n",
    " 'min_data_in_bin': 1,\n",
    " 'min_data_in_leaf': 1,\n",
    " 'num_leaves': 31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid's rmse: 7.39079\n",
      "[200]\tvalid's rmse: 4.55953\n",
      "[300]\tvalid's rmse: 3.91115\n",
      "[400]\tvalid's rmse: 3.72033\n",
      "[500]\tvalid's rmse: 3.61788\n",
      "[600]\tvalid's rmse: 3.54634\n",
      "[700]\tvalid's rmse: 3.48541\n",
      "[800]\tvalid's rmse: 3.43419\n",
      "[900]\tvalid's rmse: 3.39139\n",
      "[1000]\tvalid's rmse: 3.3526\n",
      "[1100]\tvalid's rmse: 3.31729\n",
      "[1200]\tvalid's rmse: 3.28258\n",
      "[1300]\tvalid's rmse: 3.24867\n",
      "[1400]\tvalid's rmse: 3.21567\n",
      "[1500]\tvalid's rmse: 3.18847\n",
      "[1600]\tvalid's rmse: 3.16202\n",
      "[1700]\tvalid's rmse: 3.13638\n",
      "[1800]\tvalid's rmse: 3.1117\n",
      "[1900]\tvalid's rmse: 3.09086\n",
      "[2000]\tvalid's rmse: 3.07205\n",
      "[2100]\tvalid's rmse: 3.05345\n",
      "[2200]\tvalid's rmse: 3.03853\n",
      "[2300]\tvalid's rmse: 3.02331\n",
      "[2400]\tvalid's rmse: 3.00813\n",
      "[2500]\tvalid's rmse: 2.99295\n",
      "[2600]\tvalid's rmse: 2.97928\n",
      "[2700]\tvalid's rmse: 2.96744\n",
      "[2800]\tvalid's rmse: 2.95508\n",
      "[2900]\tvalid's rmse: 2.9427\n",
      "[3000]\tvalid's rmse: 2.93155\n",
      "[3100]\tvalid's rmse: 2.92148\n",
      "[3200]\tvalid's rmse: 2.91231\n",
      "[3300]\tvalid's rmse: 2.90378\n",
      "[3400]\tvalid's rmse: 2.89667\n",
      "[3500]\tvalid's rmse: 2.88706\n",
      "[3600]\tvalid's rmse: 2.87971\n",
      "[3700]\tvalid's rmse: 2.87182\n",
      "[3800]\tvalid's rmse: 2.86573\n",
      "[3900]\tvalid's rmse: 2.85867\n",
      "[4000]\tvalid's rmse: 2.85303\n",
      "[4100]\tvalid's rmse: 2.8475\n",
      "[4200]\tvalid's rmse: 2.84123\n",
      "[4300]\tvalid's rmse: 2.83519\n",
      "[4400]\tvalid's rmse: 2.83006\n",
      "[4500]\tvalid's rmse: 2.82405\n",
      "[4600]\tvalid's rmse: 2.81925\n",
      "[4700]\tvalid's rmse: 2.81508\n",
      "[4800]\tvalid's rmse: 2.81096\n",
      "[4900]\tvalid's rmse: 2.80689\n",
      "[5000]\tvalid's rmse: 2.80285\n",
      "[5100]\tvalid's rmse: 2.80017\n",
      "[5200]\tvalid's rmse: 2.79656\n",
      "[5300]\tvalid's rmse: 2.79215\n",
      "[5400]\tvalid's rmse: 2.78858\n",
      "[5500]\tvalid's rmse: 2.78561\n",
      "[5600]\tvalid's rmse: 2.78299\n",
      "[5700]\tvalid's rmse: 2.78023\n",
      "[5800]\tvalid's rmse: 2.77684\n",
      "[5900]\tvalid's rmse: 2.77407\n",
      "[6000]\tvalid's rmse: 2.77162\n",
      "[6100]\tvalid's rmse: 2.7689\n",
      "[6200]\tvalid's rmse: 2.7668\n",
      "[6300]\tvalid's rmse: 2.76472\n",
      "[6400]\tvalid's rmse: 2.76292\n",
      "[6500]\tvalid's rmse: 2.76078\n",
      "[6600]\tvalid's rmse: 2.75903\n",
      "[6700]\tvalid's rmse: 2.7574\n",
      "[6800]\tvalid's rmse: 2.75599\n",
      "[6900]\tvalid's rmse: 2.75447\n",
      "[7000]\tvalid's rmse: 2.75277\n",
      "[7100]\tvalid's rmse: 2.75104\n",
      "[7200]\tvalid's rmse: 2.74919\n",
      "[7300]\tvalid's rmse: 2.74755\n",
      "[7400]\tvalid's rmse: 2.7462\n",
      "[7500]\tvalid's rmse: 2.7452\n",
      "[7600]\tvalid's rmse: 2.7443\n",
      "[7700]\tvalid's rmse: 2.74294\n",
      "[7800]\tvalid's rmse: 2.74136\n",
      "[7900]\tvalid's rmse: 2.74024\n",
      "[8000]\tvalid's rmse: 2.73868\n",
      "[8100]\tvalid's rmse: 2.73744\n",
      "[8200]\tvalid's rmse: 2.73681\n",
      "[8300]\tvalid's rmse: 2.73627\n",
      "[8400]\tvalid's rmse: 2.73597\n",
      "[8500]\tvalid's rmse: 2.73486\n",
      "[8600]\tvalid's rmse: 2.73362\n",
      "[8700]\tvalid's rmse: 2.73295\n",
      "[8800]\tvalid's rmse: 2.73145\n",
      "[8900]\tvalid's rmse: 2.73054\n",
      "[9000]\tvalid's rmse: 2.72987\n",
      "[9100]\tvalid's rmse: 2.72903\n",
      "[9200]\tvalid's rmse: 2.7284\n",
      "[9300]\tvalid's rmse: 2.72812\n",
      "Early stopping, best iteration is:\n",
      "[9266]\tvalid's rmse: 2.72792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9266"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgb = LGBMRegressor(n_estimators=20000, **lgb_params, random_state=123456789, n_jobs=-1)\n",
    "lgb.fit(X_trains, y_train, **lgb_fit_params)\n",
    "lgb.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_lgb=LGBMRegressor(n_estimators=int(lgb.best_iteration_*1.2), **lgb_params)\n",
    "lgb_model=clf_lgb.fit(trains, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_score=cross_val_score(X=trains,y=y,estimator=clf_lgb,scoring='neg_root_mean_squared_error',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.573120965645183"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = lgb_model.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([471.60833789, 494.40796252, 496.08309322, ..., 471.64773642,\n",
       "       444.58452749, 464.82570665])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=(0.15*y_pred1)+(y_pred2*0.15)+(y_pred3*0.7)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe2=pd.DataFrame(np.round(abs(y_pred),4),columns=['PE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe2.to_excel('D:\\pe2.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>472.459382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>493.673699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>496.046368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>480.007971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>445.407637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PE\n",
       "0  472.459382\n",
       "1  493.673699\n",
       "2  496.046368\n",
       "3  480.007971\n",
       "4  445.407637"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv('D:\\pe_sample.csv')\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([471.62713092, 494.37040789, 496.10146354, ..., 471.64508313,\n",
       "       444.56897406, 464.85053215])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1=(0.1*y_pred1)+(y_pred2*0.2)+(y_pred3*0.7)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe3=pd.DataFrame(np.round(abs(y_pred1),2),columns=['PE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe3.to_excel('D:\\pe3.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4547131871022625"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,pe2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "clf1 = xgb\n",
    "clf2 = grd\n",
    "\n",
    "sclf = StackingCVRegressor(regressors=[clf1, clf2], \n",
    "                          meta_regressor=lgb,random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: -2.674800 (+/- 0.0717) [xgb]\n",
      "Accuracy: -2.644430 (+/- 0.0807) [GradientBoost]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-b771660159b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrains\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_root_mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %0.6f (+/- %0.4f) [%s]\"\u001b[0m  \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\mlxtend\\regressor\\stacking_cv_regression.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, sample_weight)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mregr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregr_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                 \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         n_stages = self._fit_stages(\n\u001b[0;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1592\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[0;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1594\u001b[1;33m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m-> 1245\u001b[1;33m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1226\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for clf, label in zip([clf1, clf2, sclf], \n",
    "                      ['xgb', \n",
    "                       'GradientBoost',\n",
    "                       'Stacking']):\n",
    "    \n",
    "\n",
    "    scores = cross_val_score(clf, trains, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "    print(\"Accuracy: %0.6f (+/- %0.4f) [%s]\"  % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_fit_params={\"early_stopping_rounds\":200, \n",
    "            \"eval_metric\" : 'rmse', \n",
    "            \"eval_set\" : [(X_tests,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose':100\n",
    "           }\n",
    "lgb_params = {'boosting_type': 'gbdt',\n",
    " 'objective': 'regression',\n",
    " 'metric': 'rmse',\n",
    " 'verbose': 0,\n",
    " 'bagging_fraction': 0.8,\n",
    " 'bagging_freq': 1,\n",
    " 'lambda_l1': 0.01,\n",
    " 'lambda_l2': 0.01,\n",
    " 'learning_rate': 0.01,\n",
    " 'max_bin': 255,\n",
    " 'max_depth': 6,\n",
    " 'min_data_in_bin': 1,\n",
    " 'min_data_in_leaf': 1,\n",
    " 'num_leaves': 31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid's rmse: 7.39079\n",
      "[200]\tvalid's rmse: 4.55953\n",
      "[300]\tvalid's rmse: 3.91115\n",
      "[400]\tvalid's rmse: 3.72033\n",
      "[500]\tvalid's rmse: 3.61788\n",
      "[600]\tvalid's rmse: 3.54634\n",
      "[700]\tvalid's rmse: 3.48541\n",
      "[800]\tvalid's rmse: 3.43419\n",
      "[900]\tvalid's rmse: 3.39139\n",
      "[1000]\tvalid's rmse: 3.3526\n",
      "[1100]\tvalid's rmse: 3.31729\n",
      "[1200]\tvalid's rmse: 3.28258\n",
      "[1300]\tvalid's rmse: 3.24867\n",
      "[1400]\tvalid's rmse: 3.21567\n",
      "[1500]\tvalid's rmse: 3.18847\n",
      "[1600]\tvalid's rmse: 3.16202\n",
      "[1700]\tvalid's rmse: 3.13638\n",
      "[1800]\tvalid's rmse: 3.1117\n",
      "[1900]\tvalid's rmse: 3.09086\n",
      "[2000]\tvalid's rmse: 3.07205\n",
      "[2100]\tvalid's rmse: 3.05345\n",
      "[2200]\tvalid's rmse: 3.03853\n",
      "[2300]\tvalid's rmse: 3.02331\n",
      "[2400]\tvalid's rmse: 3.00813\n",
      "[2500]\tvalid's rmse: 2.99295\n",
      "[2600]\tvalid's rmse: 2.97928\n",
      "[2700]\tvalid's rmse: 2.96744\n",
      "[2800]\tvalid's rmse: 2.95508\n",
      "[2900]\tvalid's rmse: 2.9427\n",
      "[3000]\tvalid's rmse: 2.93155\n",
      "[3100]\tvalid's rmse: 2.92148\n",
      "[3200]\tvalid's rmse: 2.91231\n",
      "[3300]\tvalid's rmse: 2.90378\n",
      "[3400]\tvalid's rmse: 2.89667\n",
      "[3500]\tvalid's rmse: 2.88706\n",
      "[3600]\tvalid's rmse: 2.87971\n",
      "[3700]\tvalid's rmse: 2.87182\n",
      "[3800]\tvalid's rmse: 2.86573\n",
      "[3900]\tvalid's rmse: 2.85867\n",
      "[4000]\tvalid's rmse: 2.85303\n",
      "[4100]\tvalid's rmse: 2.8475\n",
      "[4200]\tvalid's rmse: 2.84123\n",
      "[4300]\tvalid's rmse: 2.83519\n",
      "[4400]\tvalid's rmse: 2.83006\n",
      "[4500]\tvalid's rmse: 2.82405\n",
      "[4600]\tvalid's rmse: 2.81925\n",
      "[4700]\tvalid's rmse: 2.81508\n",
      "[4800]\tvalid's rmse: 2.81096\n",
      "[4900]\tvalid's rmse: 2.80689\n",
      "[5000]\tvalid's rmse: 2.80285\n",
      "[5100]\tvalid's rmse: 2.80017\n",
      "[5200]\tvalid's rmse: 2.79656\n",
      "[5300]\tvalid's rmse: 2.79215\n",
      "[5400]\tvalid's rmse: 2.78858\n",
      "[5500]\tvalid's rmse: 2.78561\n",
      "[5600]\tvalid's rmse: 2.78299\n",
      "[5700]\tvalid's rmse: 2.78023\n",
      "[5800]\tvalid's rmse: 2.77684\n",
      "[5900]\tvalid's rmse: 2.77407\n",
      "[6000]\tvalid's rmse: 2.77162\n",
      "[6100]\tvalid's rmse: 2.7689\n",
      "[6200]\tvalid's rmse: 2.7668\n",
      "[6300]\tvalid's rmse: 2.76472\n",
      "[6400]\tvalid's rmse: 2.76292\n",
      "[6500]\tvalid's rmse: 2.76078\n",
      "[6600]\tvalid's rmse: 2.75903\n",
      "[6700]\tvalid's rmse: 2.7574\n",
      "[6800]\tvalid's rmse: 2.75599\n",
      "[6900]\tvalid's rmse: 2.75447\n",
      "[7000]\tvalid's rmse: 2.75277\n",
      "[7100]\tvalid's rmse: 2.75104\n",
      "[7200]\tvalid's rmse: 2.74919\n",
      "[7300]\tvalid's rmse: 2.74755\n",
      "[7400]\tvalid's rmse: 2.7462\n",
      "[7500]\tvalid's rmse: 2.7452\n",
      "[7600]\tvalid's rmse: 2.7443\n",
      "[7700]\tvalid's rmse: 2.74294\n",
      "[7800]\tvalid's rmse: 2.74136\n",
      "[7900]\tvalid's rmse: 2.74024\n",
      "[8000]\tvalid's rmse: 2.73868\n",
      "[8100]\tvalid's rmse: 2.73744\n",
      "[8200]\tvalid's rmse: 2.73681\n",
      "[8300]\tvalid's rmse: 2.73627\n",
      "[8400]\tvalid's rmse: 2.73597\n",
      "[8500]\tvalid's rmse: 2.73486\n",
      "[8600]\tvalid's rmse: 2.73362\n",
      "[8700]\tvalid's rmse: 2.73295\n",
      "[8800]\tvalid's rmse: 2.73145\n",
      "[8900]\tvalid's rmse: 2.73054\n",
      "[9000]\tvalid's rmse: 2.72987\n",
      "[9100]\tvalid's rmse: 2.72903\n",
      "[9200]\tvalid's rmse: 2.7284\n",
      "[9300]\tvalid's rmse: 2.72812\n",
      "[9400]\tvalid's rmse: 2.72797\n",
      "[9500]\tvalid's rmse: 2.7274\n",
      "[9600]\tvalid's rmse: 2.72659\n",
      "[9700]\tvalid's rmse: 2.72632\n",
      "[9800]\tvalid's rmse: 2.72588\n",
      "[9900]\tvalid's rmse: 2.72571\n",
      "[10000]\tvalid's rmse: 2.72523\n",
      "[10100]\tvalid's rmse: 2.72473\n",
      "[10200]\tvalid's rmse: 2.72467\n",
      "[10300]\tvalid's rmse: 2.72422\n",
      "[10400]\tvalid's rmse: 2.72385\n",
      "[10500]\tvalid's rmse: 2.72362\n",
      "[10600]\tvalid's rmse: 2.72291\n",
      "[10700]\tvalid's rmse: 2.72224\n",
      "[10800]\tvalid's rmse: 2.72156\n",
      "[10900]\tvalid's rmse: 2.72127\n",
      "[11000]\tvalid's rmse: 2.72113\n",
      "[11100]\tvalid's rmse: 2.72106\n",
      "[11200]\tvalid's rmse: 2.72105\n",
      "[11300]\tvalid's rmse: 2.72053\n",
      "[11400]\tvalid's rmse: 2.72023\n",
      "[11500]\tvalid's rmse: 2.71956\n",
      "[11600]\tvalid's rmse: 2.71932\n",
      "[11700]\tvalid's rmse: 2.7191\n",
      "[11800]\tvalid's rmse: 2.71873\n",
      "[11900]\tvalid's rmse: 2.71861\n",
      "[12000]\tvalid's rmse: 2.71854\n",
      "[12100]\tvalid's rmse: 2.71864\n",
      "[12200]\tvalid's rmse: 2.71868\n",
      "Early stopping, best iteration is:\n",
      "[12011]\tvalid's rmse: 2.71843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12011"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgb1 = LGBMRegressor(n_estimators=40000, **lgb_params, random_state=123456789, n_jobs=-1)\n",
    "lgb1.fit(X_trains, y_train, **lgb_fit_params)\n",
    "lgb1.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_lgb1=LGBMRegressor(n_estimators=int(lgb1.best_iteration_*1.2), **lgb_params)\n",
    "lgb1_model=clf_lgb1.fit(trains, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_score1=cross_val_score(X=trains,y=y,estimator=clf_lgb1,scoring='neg_root_mean_squared_error',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.561670439238864"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lgb_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = lgb1_model.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([471.87244833, 494.68762091, 495.72666352, ..., 471.95809432,\n",
       "       444.54582224, 464.60638529])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predn = (0.11*y_pred1)+(y_pred2*0.11)+(y_pred4*0.78)\n",
    "y_predn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe4=pd.DataFrame(np.round(abs(y_predn),2),columns=['PE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe4.to_excel('D:\\pe4.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb1=XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=6000,\n",
    " max_depth=10,\n",
    " colsample_bytree=0.8,\n",
    " seed=100)\n",
    "xgb_model1=xgb1.fit(trains,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_results1= cross_val_score(xgb1, trains, y,cv=5, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.5250372908992618"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xgb_results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred01 = xgb_model1.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([472.11115, 494.98642, 497.32034, ..., 472.11334, 444.50436,\n",
       "       465.81137], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd2 = GradientBoostingRegressor(learning_rate =0.01,n_estimators=6500,max_depth=8)\n",
    "grd_model2=grd2.fit(trains,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_results2= cross_val_score(grd2, trains, y,cv=5, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.6162821957456375"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(grd_results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred02 = grd_model2.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([472.07091512, 494.94919306, 496.81860105, ..., 472.07632835,\n",
       "       444.58136802, 465.305332  ])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = (0.3*y_pred4)+(y_pred01*0.6)+(y_pred02*0.1)\n",
    "y_preds                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe5=pd.DataFrame(np.round(abs(y_preds),2),columns=['PE'])  #2.214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe5.to_excel('D:\\pe5.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestRegressor( n_estimators=300,max_depth = 10,n_jobs = -1)\n",
    "\n",
    "ada = AdaBoostRegressor(base_estimator = rf,learning_rate = 0.01 ,n_estimators = 100 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_model=ada.fit(trains,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ada_results= cross_val_score(ada, trains, y,cv=5, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb2=XGBRegressor(\n",
    " learning_rate =0.01,\n",
    " n_estimators=6500,\n",
    " max_depth=10,\n",
    " colsample_bytree=0.8,\n",
    " seed=100)\n",
    "xgb_model2=xgb2.fit(trains,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results2= cross_val_score(xgb2, trains, y,cv=5, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.5246143752392753"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xgb_results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = xgb_model2.predict(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([472.10284485, 494.96175824, 497.01974855, ..., 472.10904725,\n",
       "       444.56847412, 465.4676866 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predd = (0.2*y_pred4)+(y_pred02*0.1)+(y_pred5*0.7)\n",
    "y_predd   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe6=pd.DataFrame(np.round(abs(y_predd),2),columns=['PE'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe6.to_excel('D:\\pe6.xlsx',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb3=XGBRegressor(\n",
    " learning_rate =0.03,\n",
    " n_estimators=6500,\n",
    " max_depth=10,\n",
    " colsample_bytree=0.8,\n",
    " seed=100)\n",
    "xgb_model3=xgb3.fit(trains,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results3= cross_val_score(xgb3, trains, y,cv=5, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.532006710183853"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xgb_results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
